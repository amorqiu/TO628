---
title: "Telecom Customer Churn Prediction"
author: TO 628 Group 8
date: 4/14/2020
output: html_document
---

## Introduction

The objective of this project is to predict churn or no churn in order to retain the customers in the telco company. The reason we choose this topic is that customer churn is one of the most important metrics for a business to evaluate. Customer churn impedes growth, so companies should have a sense of which kind of group are going to stop to use its product / service.

### About the data (from data description on Kaggle)

https://www.kaggle.com/blastchar/telco-customer-churn

The data set includes information about:

- Customers who left within the last month – the column is called Churn
- Services that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies
- Customer account information – how long they’ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges
- Demographic info about customers – gender, age range, and if they have partners and dependents

```{r}
library(dplyr)
library(corrplot)
library(randomForest)
library(caret)
library(kernlab)
library(neuralnet)
library(gmodels)
library(C50)
```



### Data Exploration

```{r}
data <- read.csv("Churn.csv")
```

```{r}
str(data)
```


```{r}
summary(data)
```


**Factor**
```{r}
# Factor seniorcitizen
data$SeniorCitizen <- as.factor(data$SeniorCitizen)
```


**Missing Values**
There are only 11 missing values in TotalCharges column, the number of missing values is relatively small, so we decide to remove those 11 rows.
```{r}
# remove the rows with missing value
data <- na.omit(data)
```


```{r}
data %>%
  dplyr::select (TotalCharges, MonthlyCharges, tenure) %>%
  cor() %>%
  corrplot.mixed(upper = "circle", tl.col = "black", number.cex = 0.7)
```
Correlation between tunure and TotalCharge, TotalCharges and MonthlyCharges



```{r}
#set bins of tenure 
data$tenure[data$tenure >=0 & data$tenure <= 12] <- '0-1 year'
data$tenure[data$tenure >=12 & data$tenure <= 24] <- '1-2 year'
data$tenure[data$tenure >=24 & data$tenure <= 36] <- '2-3 year'
data$tenure[data$tenure >=36 & data$tenure <= 48] <- '3-4 year'
data$tenure[data$tenure >=48 & data$tenure <= 60] <- '4-5 year'
data$tenure[data$tenure >=60 & data$tenure <= 72] <- '5-6 year'

data$tenure <- as.factor(data$tenure)
```

```{r}
#Remove customerID
data$customerID <- NULL
```

```{r}
# replace the categorical feature "No phone service" and "No Internet Service Service" to "No"
data <- data.frame(lapply(data, function(x) {
                  gsub("No internet service", "No", x)}))

data <- data.frame(lapply(data, function(x) {
                  gsub("No phone service", "No", x)}))

num_columns <- c("MonthlyCharges", "TotalCharges")
data[num_columns] <- sapply(data[num_columns], as.numeric)
```


```{r}
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}
data[num_columns] <- sapply(data[num_columns], normalize)
```



```{r}
set.seed(111)

# Split data, 80% distribution of churn for training
train.index <- createDataPartition(
    y = data$Churn, p = 0.8, list = FALSE
)
train <- data[train.index,]
test <- data[-train.index,]

```



```{r}
#Simple logistic regression
logit.model <- glm(Churn ~ ., data = train, family = "binomial")
summary(logit.model)
```


```{r}
pred <- predict(logit.model, type = "response", newdata = test)
summary(pred)
#test$prob <- pred

# Using probability cutoff of 50%.
logit.pred_churn <- factor(ifelse(pred >= 0.5, "Yes", "No"))
actual_churn <- factor(ifelse(test$Churn == "Yes","Yes","No"))



CrossTable(test$Churn, logit.pred_churn,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))
```

```{r}
#Improved logistic regression
logit.model2 <- glm(Churn ~ tenure + InternetService + SeniorCitizen + PhoneService + MultipleLines + OnlineSecurity + TechSupport + StreamingTV + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges, data = train, family = binomial) 

summary(logit.model2)
```

```{r}
pred2 <- predict(logit.model2, type = "response", newdata = test)
summary(pred2)
#test$prob <- pred

# Using probability cutoff of 50%.
logit.pred_churn2 <- factor(ifelse(pred2 >= 0.5, "Yes", "No"))
actual_churn2 <- factor(ifelse(test$Churn == "Yes","Yes","No"))

CrossTable(test$Churn, logit.pred_churn2,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))
```


```{r}
accuracy <- function(predicted, trueval, model, hideoutput = F) {
  stopifnot(length(predicted) == length(trueval))
  result <- sum(predicted == trueval) / length(predicted)
  if (!hideoutput) {cat("Model:", model, "had", result, "accuracy\n")}
  return(result)
}
```



```{r}
decisionTree <- C5.0(train[-20], train$Churn)
decisionTree_pred <- predict(decisionTree, test)
CrossTable(test$Churn, decisionTree_pred, prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,dnn = c('actual default', 'predicted default'))
```
```{r}
acc_dt = accuracy(decisionTree_pred, test$Churn, "Random Forest Classification", TRUE)
acc_dt
```



```{r}
#RandomForest Model
rf.model <- randomForest(Churn ~ ., data = train)
rfpred <- predict(rf.model, newdata = test)
#summary(rfpred)
CrossTable(test$Churn, rfpred, prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,dnn = c('actual default', 'predicted default'))
```


```{r}
acc_rf = accuracy(rfpred, test$Churn, TRUE)
acc_rf
```

```{r}
boost100 <- C5.0(train[-20], train$Churn, trials = 100)
boost_pred100 <- predict(boost100, test)
CrossTable(test$Churn, boost_pred100, prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,dnn = c('actual default', 'predicted default'))
```

```{r}
acc_rf_boost = accuracy(boost_pred100, test$Churn, "Random Forest Classification", TRUE)
acc_rf_boost
```


```
SVM's
```

```{r}
# SVM model
churn_classifier <- ksvm(Churn ~ ., data = train, kernel = "besseldot")
# predictions on testing dataset
churn_predictions <- predict(churn_classifier, test)
head(churn_predictions)

CrossTable(test$Churn, churn_predictions,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))
```


```{r}
# look only at agreement vs. non-agreement
# construct a vector of TRUE/FALSE indicating correct/incorrect predictions
agreement <- churn_predictions == test$Churn
table(agreement)
prop.table(table(agreement))

```
```{r}
# different kernels are different mathmetical functions, the second SVM model
churn_classifier_rbf <- ksvm(Churn ~ ., data = train, kernel = "rbfdot")
churn_predictions_rbf <- predict(churn_classifier_rbf, test)
agreement_rbf <- churn_predictions_rbf == test$Churn
table(agreement_rbf)
prop.table(table(agreement_rbf))
```
```{r}
CrossTable(test$Churn, churn_predictions_rbf,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))
```
```
Based on the two cross tables, the second model with the rbfdot kernel has a bettwe result.
```

```
KNN
```

```{r}
library(class)

train_label<-train$Churn
test_label<-test$Churn


knn_train_data <- as.data.frame(model.matrix(~ . -1,data=train))
knn_train_data<-knn_train_data[-20]

knn_test_data <- as.data.frame(model.matrix(~ . -1,data=test))
knn_test_data<-knn_test_data[-20]

```

```{r}

test_pred55 <- knn(train = knn_train_data, test = knn_test_data, cl = train_label, k = 55)

CrossTable(test_label, test_pred55)
p1=(1023 + 335) / 1405

```

```{r}
test_pred_3 <- knn(train = knn_train_data, test = knn_test_data, cl = train_label,k = 3)
CrossTable(test_label, test_pred_3)
p2=(338 + 1012) / 1405
```

```{r}
test_pred_21 <- knn(train = knn_train_data, test = knn_test_data, cl = train_label, k = 21)
CrossTable(test_label, test_pred_21)
p3=(1025 + 345) / 1405
```

```{r}
test_pred_59 <- knn(train = knn_train_data, test = knn_test_data, cl = train_label, k = 59)
CrossTable(test_label, test_pred_59)
p4=(1022+334)/1405
```



```{r}
accuracy <- function(predicted, trueval, model, hideoutput = F) {
  stopifnot(length(predicted) == length(trueval))
  result <- sum(predicted == trueval) / length(predicted)
  if (!hideoutput) {cat("Model:", model, "had", result, "accuracy\n")}
  return(result)

}
```



```{r}
a1 = accuracy(logit.pred_churn, test$Churn, "Log Prediction Plain", TRUE)
a2 = accuracy(logit.pred_churn2, test$Churn, "Log Prediction advanced", TRUE)
a3 = accuracy(decisionTree_pred, test$Churn, "Decision Tree", TRUE)
a4 = accuracy(boost_pred100, test$Churn, "Decision Tree with boost100", TRUE)
a5 = accuracy(rfpred, test$Churn, "Random Forest", TRUE)
a6 = accuracy(churn_predictions, test$Churn, "SVM(besseldot) ", TRUE)
a7 = accuracy(churn_predictions_rbf, test$Churn, "SVM(rdf)", TRUE)
a8 = accuracy(test_pred_21, test$Churn, "KNN(21)", TRUE)
a9 = accuracy(test_pred_59, test$Churn, "KNN(59)", TRUE)

```

```{r}
acc_predictions = c(a1,a2,a3,a4,a5,a6,a7,a8,a9)
names = c("Log Prediction Plain","Log Prediction advanced","Decision Tree","Decision Tree with boost100","Random Forest","SVM(besseldot)","SVM(rdf)","KNN(21)","KNN(59)")

acc_mat <- data.frame(ModelName = names, accuracy = acc_predictions) %>% print
```




```{r}
dotchart(acc_predictions, labels = names, main = "Accuracy of the models", xlab = "Accuracy")
```

```{r}
log_prediction_train <- predict(logit.model, type = "response", newdata = train)
log_prediction_train <- factor(ifelse(log_prediction_train >= 0.5, "Yes", "No"))


log_prediction_train_advanced <- predict(logit.model2, type = "response", newdata = train)
log_prediction_train_advanced <- factor(ifelse(log_prediction_train_advanced >= 0.5, "Yes", "No"))


decision_prediction_train <- predict(decisionTree, train)
rf_prediction_train <- predict(rf.model, newdata = train)
boost100_prediction_train <- predict(boost100, train)

svm_prediction_train <- predict(churn_classifier, train)
svm_rbf_prediction_train <- predict(churn_classifier_rbf, train)


knn59_prediction_train <- knn(train = knn_train_data, test = knn_train_data, cl = train_label, k = 59)
knn21_prediction_train <- knn(train = knn_train_data, test = knn_train_data, cl = train_label, k = 21)
```



```{r}
ConvertToYesNo <- function(myprediction) {
  result <- myprediction %>% as.factor()
  levels(result) <- c("no", "yes")
  result
}
```


```{r}
logit.pred_churn <- ConvertToYesNo(logit.pred_churn)
logit.pred_churn2 <- ConvertToYesNo(logit.pred_churn2)
decisionTree_pred <- ConvertToYesNo(decisionTree_pred)
boost_pred100 <- ConvertToYesNo(boost_pred100)
rfpred <- ConvertToYesNo(rfpred)
churn_predictions <- ConvertToYesNo(churn_predictions)
churn_predictions_rbf <- ConvertToYesNo(churn_predictions_rbf)
test_pred_21 <- ConvertToYesNo(test_pred_21)
test_pred_59 <- ConvertToYesNo(test_pred_59)
```


```{r}
stacked_data = data.frame(logit.pred_churn, logit.pred_churn2, decisionTree_pred, boost_pred100, rfpred, churn_predictions, churn_predictions_rbf, test_pred_21, test_pred_59) %>% as.tbl()

```


```{r}
model_combined_results <- data.frame(log_prediction_train, log_prediction_train_advanced, decision_prediction_train, rf_prediction_train, boost100_prediction_train, svm_prediction_train, svm_rbf_prediction_train, knn59_prediction_train, knn21_prediction_train) %>% as.tbl()
```


```{r}
library(party)
stacked_model <- ctree(train$Churn ~ . , data = model_combined_results)
```


```{r}
stacked_model_prediction = predict(stacked_model, train, type = "response")
accuracy(stacked_model_prediction, train$Churn, "Decision Tree", TRUE)
```
